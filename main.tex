\documentclass[11pt]{article}
\usepackage[letterpaper]{geometry}
\usepackage{times}
\geometry{top=1.0in, bottom=1.0in, left=1.0in, right=1.0in}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{fancyvrb} %Need for ventering verbatim using BVerbatim
\pagestyle{fancy}
\fancyhf{}
\rhead{Reichelt \thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
%To make sure we actually have header 0.5in away from top edge
%12pt is one-sixth of an inch. Subtract this from 0.5in to get headsep value
\setlength\headsep{0.333in}


% Packages related to figures
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[font=scriptsize,labelfont=bf, justification=centering]{caption}

% Text formatting packages and macros
%\doublespacing
%\usepackage[document]{ragged2e}
%\setlength\RaggedRightParindent{4em}
\setlength\parindent{2em}

% Reformat section styles
\usepackage{titlesec}
\titleformat{\section}
  {\normalfont\fontsize{11}{11}\bfseries\scshape}{\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\fontsize{9}{9}\bfseries\itshape}{\thesection}{1em}{}

\titleformat{\subsubsection}
  {\normalfont\fontsize{7}{7}\itshape}{\thesection}{1em}{}


\newcommand{\bibent}{\noindent \hangindent 40pt}
\newenvironment{workscited}{\newpage \begin{center} Works Cited \end{center}}{\newpage }
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[group-separator={,}]{siunitx}
\newcommand{\TODO}[1]{\textcolor{red}{[#1]}}
\newcommand{\PASS}[1]{\verb| #1|}

% Math related packages
\usepackage[fleqn]{amsmath}
\usepackage{esvect}

% Algorithm package
\usepackage{algorithmic}
\usepackage{algorithm}

\begin{document}

    \thispagestyle{empty}
    \begin{flushleft}
        Scott Reichelt\\
        Dr. Scott Herring\\
        UWP104E - Section 2\\
        \today\\
    \end{flushleft}
    \vspace{1em}
    \begin{center}
        Review of Originating Work on Whale Optimization Algorithm and Subsequent Applications
    \end{center}

\section*{Introduction}
Since there introduction in \TODO{year, reference} with \TODO{author, algorithm} swarm algorithms have proven competitive with other meta-heuristic algorithms, and are attractive models because of their underlying simplicity.
Swarm algorithms are also attractive because they are relatively easy to implement, do not rely on knowledge of the gradient, can overcome problems posed by local optima, and can be adapted for a wide range of optimization problems (Mirjalili \& Lewis 2016).
Meta-heuristic approaches appeared in the literature in the 1960s with algorithms modeled in Evolution, while algorithms modeled on swarm intelligence first appeared in 1992 with Marco Dorigo's Ant Colony Optimization (Wahab et al 2015).
The Whale Optimization Algorithm (WOA) is the most recent swarm based meta-heuristic algorithm, and has quickly proved itself as a competitive general purpose optimization approach (Mirjalili \& Lewis 2016).

\subsection*{The Whale Optimization Algorithm (WOA)}
\TODO{Talk about WOA in specific terms, bridge gap between swarm algorithm and humpback whale stuff}
The WOA draws its inspiration from a hunting behavior recorded in rare populations of humpback whales called bubble-net feeding, which is a technique that allows groups of whales to efficiently corral and consume small fish (Wiley et al. 2011).
The algorithm uses both the whale's swarming behavior that seeks out potential prey as the exploration phase of the meta-heuristic and the cooperative attack pattern known as bubble-net for the exploitation phase.
\TODO{Maybe remove this sentence to a later section and discuss the high level algorithm better here}

\subsubsection*{Bubble-net Foraging: Cetological Background}
The hunting behavior which informs the WOA involves a swarm of humpback whales finding a target school of fish, encircling the prey, and executing a bubble-net.
Once the school of fish has been herded the swarm cooperatively executes a capture method to optimally consume fish with the most interesting behavior coming from a single whale who executes a bubble-net maneuver.
The bubble-netting whale dives below the target prey and encircles it with a column of bubbles purposefully emanating from its blow hole (Wiley et al 2011).
The bubbles form an impassable barrier (Wiley et al. 2011) for the fish, and concentric circles corral target prey into a shrinking area through either an upward-spiral or double loop maneuver (Wiley et al. 2011).
The infographic in figure 1 demonstrates the cooperative roles of the hunting method.
The ring of bubbles forming the bubble-net can be seen from the surface of the water (figure 2), and as the column of bubbles corrals prey the team of humpback whales lunge from the columns center to feed as seen in figure 3.

\begin{figure}[h]
	\caption{Bubble-net foraging infographic courtesy of www.INCA.com}
	\includegraphics[width=\textwidth]{working-together.jpeg}
\end{figure}

\begin{minipage}{0.45\textwidth}
	\begin{figure}[H]
		\centering
		\caption{Bubble spiral aerial view courtesy of NOAA}
		\includegraphics[width=0.9\textwidth]{spiral.jpg}
	\end{figure}
\end{minipage}
\begin{minipage}{0.45\textwidth}
	\begin{figure}[H]
		\centering
		\caption{Humpback whales lunging through the center of a completed bubble net}
		\includegraphics[width=\textwidth]{lunge.jpg}
	\end{figure}
\end{minipage}


\subsubsection*{Mathematically Modeling the Bubble-Net Behavior}
In the exploration phase of the algorithm whales are dispersed throughout the search space using a stochastic process, and will iteratively migrate towards the current best candidate solution (Mirjalili 2016) according to equations 1--4.

\begin{equation}
	\vec{D} = |\vec{C}\cdot\vec{X}^*(t) - \vec{X}(t)|
\end{equation}

\begin{equation}
	\vec{X}(t + 1) = |\vec{X}(t) - \vec{A}\cdot\vec{D})|
\end{equation}

\begin{equation}
	\vec{A} = 2\vec{a}\cdot\vec{r}-\vec{a}
\end{equation}

\begin{equation}
	\vec{C} = 2\cdot\vec{r}
\end{equation}

Where $\cdot$ is element by element multiplication, $| |$ is the absolute value, $\vec{X}^*$ is the current best best solution, $\vec{A}$ and $\vec{C}$ are coefficient vectors and $t$ denotes the current iteration (Mirjalili 2016).
The vector $\vec{a}$ decreseases linearly from $2$ to $0$ and $\vec{r}$ is a random vector in $[0,1]$ (Mirjalili 2016) $\vec{r}$ is needed to ensure all points in the search space are reachable, and $\vec{a}$ gradually shrinks the search space.
Equations 1--4 model the basic encircling of prey preformed by the swarm of whales and easily extends to n-dimensional space where the search agents occupy a hypercube (Mirjalili 2016).

The exploration phase of the algorithm relies on stochastic principles by using a random search agent in place of the best according to equations 5--6.

\begin{equation}
	\vec{D} = |\vec{C}\cdot\vec{X}_{rand} - \vec{X}|
\end{equation}

\begin{equation}
	\vec{X}(t+1) = \vec{X}_{rand} - \vec{A}\cdot\vec{D}
\end{equation}

The exploitation phase of the algorithm also uses a stochastic process to improve convergence by randomly using either the spiral or double loop attack pattern on a candidate solution.
Equation 7 introduces a spiral pattern and a mechanism to randomly switch between the spiral and encircling behaviors.

\begin{equation}
	\vec{X}(t+1) =
	\begin{cases}
		\vec{X}^*(t) - \vec{A}\cdot\vec{D} &if \; p < 0.5\\
		\vec{D}'\cdot e^{bl} \cdot cos(2\pi l) + \vec{X}^*(t) &if \; p \geq 0.5\\
   \end{cases}
\end{equation}

Where $b$ is a constant for the logarithmic spiral and $l$ is a random number in $[-1, 1]$ (Mirjalili 2016).

\begin{figure}{t}
	\caption{WOA pseudo code (Mirjalili \& Lewis 2016)}
	\begin{algorithm}[H]
		\algsetup{linenosize=\tiny}
		\scriptsize
		\begin{algorithmic}[1]
			\STATE Initialize the whales population $X_i(i = 1,2, \dots, n)$
			\STATE Calculate the fitness of each search agent
			\STATE $X^* = $ the best search agent
			\WHILE {$t <$ maximum number of iterations}
				\FOR {each search agent}
					\STATE update a, A, C, l, and p
					\IF {$p < 0.5$}
						\IF {$|A| < 1$}
							\STATE Update the position of the current search agent by Equation 1
						\ELSE
							\STATE Select a random search agent ($X_{rand}$)
							\STATE Update the position of the current search agent by Equation 6
						\ENDIF
					\ELSE
						\STATE Update the position of the current search by Equation 7
					\ENDIF
				\ENDFOR
				\STATE Check if any search agent goes beyond the search space and amend it
				\STATE Calculate the fitness of each search agent
				\STATE Update $X^*$ if there is a better solution
				\STATE $t = t+1$
			\ENDWHILE
			\STATE \RETURN $X^*$ 
		\end{algorithmic}
	\end{algorithm}
\end{figure}

\subsubsection*{Algorithm Implementation and Benchmark Results}
The pseudo code for the WOA in figure 4 is a testament to how simple meta-heuristic swarm algorithms can be in practice.
The transition between exploration and exploitation is facilitated by $\vec{A}$ gradually reducing in size (Mirjalili \& Lewis 2016), and the entire process utilizes random chance through $p$ and $X_{rand}$.
The algorithm is demonstratively competitive with both canon swarm algorithms---ie Particle Swarm Optimization---as well as more mature classes of meta-heuristics like Evolutionary algorithms (Mirjalili 2016), and its reliance on only 2 parameters $(A$ and $C)$ makes it a very attractive option for research.
In the initial benchmarks Mirjalili \& Lewis used the WOA converged either most or second most efficiently in 29 tests comparing representative meta-heuristics like Particle Swarm Optimization, Gravitational Search Algorithm, and Differential Evolution Algorithm.

\section*{WOA Applications and Evolution}
\subsection*{Data Mining}
Modern scale problems with vast amounts of available data can be approached using swarm algorithms, particularly when they are enhanced with the parallel computing techniques---i.e. partitioning the search space---that the algorithms easily accommodate (Cicirelli 2015).

\TODO{Insert pseudocode algorithm as a figure}

\TODO{Talk about the code, and benchmark results}

%\subsection*{Neural Net Feature Reduction}
%\subsection*{Augmented WOA approaches}

\begin{workscited}

\bibent
Cicirelli, F. (2015). Strategies for Parallelizing Swarm Intelligence Algorithms. 23RD EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED, AND NETWORK-BASED PROCESSING (PDP 2015), 329-336.

\bibent
Sayed, G. (2017). Breast Cancer Diagnosis Approach Based on Meta-Heuristic Optimization Algorithm Inspired by the Bubble-Net Hunting Strategy of Whales. Genetic and Evolutionary Computing : Proceedings of the Tenth International Conference on Genetic and Evolutionary Computing, November 7-9, 2016 Fuzhou City, Fujian Province, China /, 536, 306-313.

\bibent
Mirjalili, S. (2016). The Whale Optimization Algorithm. Advances in Engineering Software, 95, 51-67.

\bibent
Ab Wahab, Mohd Nadhir, Samia Nefti-Meziani, and Adham Atyabi. “A Comprehensive Review of Swarm Optimization Algorithms.” Ed. Catalin Buiu. PLoS ONE 10.5 (2015): e0122827. PMC. Web. 19 Feb. 2018.

\bibent
Wiley, D. (2011). Underwater components of humpback whale bubble-net feeding behaviour. Behaviour., 148(5-6), 575-602.

\bibent
Rohani, M. (2016). THE WORKFLOW PLANNING OF CONSTRUCTION SITES USING WHALE OPTIMIZATION ALGORITHM (WOA). TURKISH ONLINE JOURNAL OF DESIGN ART AND COMMUNICATION, 6, 2938-2950.

\bibent %figure 1
Two humpback whales bubble net feeding. Image collected under MMPA research permit \#17355.
Credit: NOAA Fisheries/Allison Henry

\bibent %figure 2
By Evadb; Edit by jjron. (Own work) [Public domain], via Wikimedia Commons

\end{workscited}

\end{document}
\}
